import re
import json
from typing import Any, List, Dict, Optional

class GuessNumAgent():
    """
    Agent that uses an injected LLM provider for feedback-driven iterative guessing.
    Now protocol-aware: all communications follow the communication protocol.
    
    In the new game mode, agents:
    - Receive per-step feedback on whether their guess is correct
    - Communicate their guess history and feedback to other agents via protocol messages
    - Use LLM to reason about next guess based on feedback patterns
    """

    def __init__(self, agent_id: str, provider, protocol: str, initial_guess: int = 0, num_choices: int = 10):
        self.agent_id = agent_id
        self.provider = provider
        self.protocol = protocol
        self.initial_guess = initial_guess
        self.current_guess = initial_guess
        self.num_choices = num_choices
        self.num_agents: Optional[int] = None
        self.current_step: int = 0
        
        # Track game state
        self.received_messages: List[Dict[str, Any]] = []
        self.last_observation: Optional[Dict[str, Any]] = None
        self.is_correct: bool = False
        self.guess_history: List[int] = [self.initial_guess]
        self.feedback_history: List[bool] = []  # True if correct, False if incorrect
        
        # LLM interaction tracking
        self.last_prompt: Optional[str] = None
        self.last_llm_output: Optional[str] = None
        self._last_message: Optional[Dict[str, Any]] = None  # Message generated by LLM in send_message()

    def reset(self) -> None:
        self.current_guess = self.initial_guess
        self.guess_history = [self.initial_guess]
        self.feedback_history = []
        self.received_messages = []
        self.is_correct = False
        self.current_step = 0
        self._last_message = None
        self.last_prompt = None
        self.last_llm_output = None

    def update_observation(self, observation: Dict[str, Any]) -> None:
        """Update agent state based on environment feedback."""
        self.last_observation = observation
        if "is_correct" in observation:
            self.is_correct = observation["is_correct"]
            self.feedback_history.append(self.is_correct)

    def receive_messages(self, messages: Dict[str, Any]) -> None:
        """Receive protocol-validated messages from other agents."""
        self.received_messages.append(messages)

    def send_message(self) -> Dict[str, Any]:
        """
        Generate a message using LLM that follows the communication protocol.
        This message includes the agent's current state and reasoning.
        
        The LLM generates the complete message based on the protocol,
        which can include state information, reasoning, etc.
        """
        # Build prompt with protocol file content
        prompt = self._build_protocol_aware_prompt()
        self.last_prompt = prompt
        # print(f"[Agent {self.agent_id}] LLM Prompt:\n{prompt}\n")

        # Call LLM provider
        llm_output = self.provider.call(prompt)
        self.last_llm_output = llm_output
        # print(f"[Agent {self.agent_id}] LLM Output:\n{llm_output}\n")
        
        # Parse JSON message from LLM output
        message = self._parse_llm_message(llm_output)
        self._last_message = message  # Store for later use in act()
        
        return message

    def act(self) -> int:
        """
        Decide next action based on environment feedback.
        
        Extracts the answer from the message previously generated by LLM in send_message().
        """
        self.current_step += 1

        # If already correct, stay with current guess
        # if self.is_correct:
        #     return self.current_guess

        # Extract answer from the LLM-generated message
        if self._last_message is not None:
            new_guess = self._last_message.get('next_guess')
            
            if new_guess is not None and isinstance(new_guess, int):
                self.current_guess = new_guess
                self.guess_history.append(new_guess)

        return self.current_guess

    def _parse_llm_message(self, llm_output: str) -> Dict[str, Any]:
        """
        Parse JSON message from LLM output with robust error handling.
        Strips any 'think' or reasoning content, applies JSON fixes, and uses regex fallback.
        """
        cleaned_output = llm_output.strip()

        # 1 Remove <think>...</think> blocks (DeepSeek / Qwen style)
        cleaned_output = re.sub(
            r"<think>.*?</think>",
            "",
            cleaned_output,
            flags=re.DOTALL | re.IGNORECASE,
        ).strip()

        # 2 Remove common reasoning prefixes (OpenAI / Claude style)
        reasoning_markers = [
            "Thoughts:",
            "Reasoning:",
            "Analysis:",
            "Chain of thought:",
            "Final Answer:",
        ]
        for marker in reasoning_markers:
            if marker in cleaned_output:
                cleaned_output = cleaned_output.split(marker, 1)[-1].strip()

        # 3 Remove Markdown code blocks (```json ... ```)
        cleaned_output = re.sub(r'^```(?:json)?\s*', '', cleaned_output, flags=re.IGNORECASE)
        cleaned_output = re.sub(r'\s*```$', '', cleaned_output)

        # 4 Try direct JSON parsing
        try:
            return json.loads(cleaned_output)
        except json.JSONDecodeError:
            pass

        # 5 Fallback: extract the last JSON object and attempt auto-repair
        matches = list(re.finditer(r"\{.*?\}", cleaned_output, flags=re.DOTALL))
        if matches:
            json_candidate = matches[-1].group()
            
            # Try parsing the extracted JSON first
            try:
                return json.loads(json_candidate)
            except json.JSONDecodeError:
                # Attempt to fix common JSON syntax errors
                fixed_json = self._attempt_json_repair(json_candidate)
                if fixed_json:
                    try:
                        return json.loads(fixed_json)
                    except json.JSONDecodeError:
                        pass

        # 6 Last resort: extract 'next_guess' field directly using regex
        next_guess = self._extract_next_guess_smart(cleaned_output)
        return {"next_guess": next_guess, "message_content": cleaned_output}

        # 7 Fail loudly with diagnostic info
        raise ValueError(
            "Could not parse final JSON message from LLM output after removing reasoning.\n"
            f"Original output:\n{llm_output}"
            f"\nCleaned output:\n{cleaned_output}"
        )

    def _attempt_json_repair(self, json_str: str) -> Optional[str]:
        """
        Attempt to repair common JSON syntax errors.
        Returns repaired JSON string or None if repair fails.
        
        Fixes:
        - Single quotes to double quotes
        - Trailing commas
        - Unquoted strings in values
        - Extra/missing brackets
        """
        repaired = json_str.strip()
        
        # 1 Replace single quotes with double quotes (be careful with apostrophes)
        # Match patterns like 'key' or 'value' (whole word/phrase in quotes)
        repaired = re.sub(r"'([^']*)'", r'"\1"', repaired)
        
        # 2 Remove trailing commas before closing braces/brackets
        repaired = re.sub(r',(\s*[}\]])', r'\1', repaired)
        
        # 3 Fix common unquoted boolean/null values that should be unquoted in JSON
        # But only if they appear as values (after colon)
        repaired = re.sub(r':\s*([Tt]rue)', r': true', repaired)
        repaired = re.sub(r':\s*([Ff]alse)', r': false', repaired)
        repaired = re.sub(r':\s*([Nn]ull)', r': null', repaired)
        
        # 4 Attempt to fix mismatched brackets (count and balance)
        open_braces = repaired.count('{')
        close_braces = repaired.count('}')
        if open_braces > close_braces:
            repaired += '}' * (open_braces - close_braces)
        elif close_braces > open_braces:
            # Remove excess closing braces from the end
            while repaired.count('}') > repaired.count('{'):
                repaired = repaired.rstrip('}').rstrip()
        
        # 5 Try to escape unescaped quotes within string values
        # This is tricky, so we use a simple heuristic: escape quotes that aren't already escaped
        repaired = re.sub(r'(?<!\\)"(\w+)"(?=\s*:)', r'"\1"', repaired)  # Key pattern
        
        return repaired

    def _extract_next_guess_smart(self, text: str) -> Optional[int]:
        """
        Use regex to extract 'next_guess' value directly from text.
        Handles various formats, JSON malformations, and null/None values.
        
        Looks for patterns like:
        - "next_guess": 5
        - "next_guess": "5"  
        - 'next_guess': 5
        - next_guess: 5
        - Also handles: null, None, undefined (returns None)
        """
        # First, try to extract numeric values
        numeric_patterns = [
            r'["\']?next_guess["\']?\s*:\s*["\']?(\d+)["\']?',
            r'["\']?next_guess["\']?\s*=\s*["\']?(\d+)["\']?',  # = instead of :
            r'next_guess["\']?\s*[:\=]\s*["\']?(\d+)',  # More flexible
        ]
        
        for pattern in numeric_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    return int(match.group(1))
                except (ValueError, IndexError):
                    continue
        
        # Check if next_guess is explicitly set to null/None/undefined
        null_patterns = [
            r'["\']?next_guess["\']?\s*[:\=]\s*(null|None|undefined)',
        ]
        
        for pattern in null_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                # Found null/None/undefined, explicitly return None
                return None
        
        return None

    def _build_protocol_aware_prompt(self) -> str:
        """
        Build a prompt with the protocol file content.
        Very simple: just read the file and insert it into the prompt.
        """
        lines = [
            f"You are {self.agent_id} playing a collaborative guessing game with other agents.",
            f"The number to guess is an integer within a specified range (0 -> {self.num_choices - 1}).",
            "Only one number is correct in each game.",
            "",
            "===== COMMUNICATION PROTOCOL =====",
            self.protocol,
            "===== END PROTOCOL =====",
            "",
            f"Current state:",
            f"  - Agent ID: {self.agent_id}",
            f"  - My guess: {self.current_guess}",
            f"  - Step: {self.current_step}",
            f"  - Correct: {self.is_correct}",
            f"  - Guess history: {self.guess_history}",
            f"  - Feedback history: {self.feedback_history}",
        ]
        
        # Add other agents' messages if any
        if self.received_messages:
            lines.append("")
            lines.append("Other agents' recent messages:")
            for msg in self.received_messages[-3:]:
                lines.append(f"  {json.dumps(msg)}")
        
        lines.extend([
            "",
            "===== COLLABORATIVE REASONING RULES =====",
            "You MUST consider other agents' feedbacks and your current state.",
            "",
            "Rules you MUST follow:",
            "1. If no one has found the correct number, choose a new guess that has not been guessed by any one.",
            "2. If anyone has found the correct number, choose it as your next answer."
        ])

        lines.extend([
            "",
            "===== OUTPUT RULES =====",
            "Following the protocol, return ONLY the JSON message without any other text or label (```json or ```):",
            "Your JSON message MUST be correct in JSON grammar.",
            "Include the 'next_guess' field with the correct number.",
        ])
        
        return "\n".join(lines)
